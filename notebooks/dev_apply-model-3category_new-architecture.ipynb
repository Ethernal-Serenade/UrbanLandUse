{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development: Applying 3-Category Classifier with New Architecture\n",
    "Utilize already-trained model to classify input data, within the new chips & catalog paradigm.  \n",
    "\n",
    "Two main modes of application:  \n",
    "(1) Apply to arbitrary set of catalog data to generate scores;  \n",
    "(2) Apply to imagery tiles in order to generate comprehensive LULC maps  \n",
    "\n",
    "Both of these modes will be captured in a single notebook, with the intention that each can be executed independently.  \n",
    "For starters, notebook will cover (2).\n",
    "  \n",
    "Date: 2019-02-11  \n",
    "Author: Peter Kerins  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "(may be over-inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python36.zip', '/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python3.6', '/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python3.6/lib-dynload', '', '/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python3.6/site-packages', '/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python3.6/site-packages/IPython/extensions', '/home/Taufiq.Rashid/.ipython', '/home/Taufiq.Rashid/UrbanLandUse', '/home/Taufiq.Rashid/UrbanLandUse', '/home/Taufiq.Rashid/UrbanLandUse', '/home/Taufiq.Rashid/UrbanLandUse', '/home/Taufiq.Rashid/UrbanLandUse']\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "# typical, comprehensive imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "import shapely\n",
    "import cartopy\n",
    "import geojson\n",
    "import fiona\n",
    "import gdal\n",
    "import h5py\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import ogr, gdal\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import math\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Add, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import descarteslabs as dl\n",
    "\n",
    "ULU_REPO = os.environ[\"ULU_REPO\"]\n",
    "sys.path.append(ULU_REPO)\n",
    "print (sys.path)\n",
    "\n",
    "import utils.util_rasters\n",
    "import utils.util_vectors\n",
    "import utils.util_training\n",
    "from utils.image_generator import ImageGenerator\n",
    "import utils.util_imagery\n",
    "import utils.util_workflow\n",
    "import utils.util_chips\n",
    "from utils.catalog_generator import CatalogGenerator\n",
    "import utils.util_scoring\n",
    "import utils.util_network\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "data_root='/data/phase_iv/'\n",
    "\n",
    "resolution = 5  # Lx:15 S2:10\n",
    "\n",
    "# tiling\n",
    "tile_resolution = resolution\n",
    "tile_size = 256\n",
    "tile_pad = 32\n",
    "\n",
    "\n",
    "# misc\n",
    "s2_bands=['blue','green','red','nir','swir1','swir2','alpha']; suffix='BGRNS1S2A'  # S2, Lx\n",
    "\n",
    "# ground truth source: aue, aue+osm, aue+osm2\n",
    "label_suffix = 'aue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_label = {0:'Open Space',1:'Non-Residential',\\\n",
    "                   2:'Residential Atomistic',3:'Residential Informal Subdivision',\\\n",
    "                   4:'Residential Formal Subdivision',5:'Residential Housing Project',\\\n",
    "                   6:'Roads',7:'Study Area',8:'Labeled Study Area',254:'No Data',255:'No Label'}\n",
    "\n",
    "cats_map = {}\n",
    "cats_map[0] = 0\n",
    "cats_map[1] = 1\n",
    "cats_map[2] = 2\n",
    "cats_map[3] = 2\n",
    "cats_map[4] = 2\n",
    "cats_map[5] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input stack and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window = 17\n",
    "\n",
    "# bands stuff outdated! needs to be reconciled with catalog filtering\n",
    "# will ignore for the moment since this is a bigger fix...\n",
    "# haven't done any examples yet incorporating additional chips beyond s2\n",
    "# into construction of a training sample\n",
    "bands_vir=s2_bands[:-1]\n",
    "bands_sar=None\n",
    "bands_ndvi=None\n",
    "bands_ndbi=None\n",
    "bands_osm=None\n",
    "\n",
    "# this can get updated when cloudmasking is added\n",
    "haze_removal = False\n",
    "\n",
    "batch_size = 128\n",
    "balancing = None\n",
    "\n",
    "# move as appropriate\n",
    "\n",
    "model_id = '3cat_14ct_green_2017_2-img-bl'\n",
    "unflatten_input = True # is the model a cnn?\n",
    "n_cats = 3 # number of categories\n",
    "\n",
    "water_overwrite = False\n",
    "water_mask = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vir 6\n"
     ]
    }
   ],
   "source": [
    "stack_label, feature_count = utils.util_workflow.build_stack_label(\n",
    "        bands_vir=bands_vir,\n",
    "        bands_sar=bands_sar,\n",
    "        bands_ndvi=bands_ndvi,\n",
    "        bands_ndbi=bands_ndbi,\n",
    "        bands_osm=bands_osm,)\n",
    "print(stack_label, feature_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model: score results\n",
    "Apply model to some set of chips and compare its predictions to the actual LULC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 17, 17, 6)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 17, 17, 32)   1760        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 17, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 17, 17, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 17, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 17, 17, 32)   1312        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 17, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 17, 17, 32)   1312        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 17, 17, 32)   128         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 32)     1024        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9, 9, 32)     128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9, 9, 32)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 9, 9, 32)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 9, 9, 64)     2336        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 64)     256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9, 9, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 9, 9, 64)     4672        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 64)     256         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5, 5, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          819712      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            1539        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 3)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 846,115\n",
      "Trainable params: 845,539\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n",
      "testing py 3 migration\n",
      "2556404\n",
      "34865\n",
      "34865\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/Taufiq.Rashid/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 445, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"/home/Taufiq.Rashid/UrbanLandUse/utils/catalog_generator.py\", line 83, in __getitem__\n    inputs=self._get_inputs()\n  File \"/home/Taufiq.Rashid/UrbanLandUse/utils/catalog_generator.py\", line 91, in _get_inputs\n    im = self._construct_sample(im)\n  File \"/home/Taufiq.Rashid/UrbanLandUse/utils/catalog_generator.py\", line 119, in _construct_sample\n    assert image.shape[1] == image.shape[2]\nAssertionError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bb219c82c4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m#predict_generator(generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         predictions = network.predict_generator(generator, steps=generator.steps, verbose=1,\n\u001b[0;32m---> 79\u001b[0;31m                           use_multiprocessing=True, max_queue_size=40, workers=64,)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         verbose=verbose)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_callback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(output_generator, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Returning `None` will trigger looping to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geoml/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "place_images = {}\n",
    "place_images['hindupur']=['U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "# place_images['singrauli']=['O','P','Q','R','S','T','U']\n",
    "# place_images['vijayawada']=['H','I']\n",
    "# place_images['jaipur']=['T','U','W','X','Y','Z']\n",
    "# place_images['hyderabad']=['P','Q','R','S','T','U']\n",
    "# place_images['sitapur']=['Q','R','T','U','V']\n",
    "# place_images['kanpur']=['AH', 'AK', 'AL', 'AM', 'AN']\n",
    "# place_images['belgaum']=['P','Q','R','S','T']\n",
    "# place_images['parbhani']=['T','V','W','X','Y','Z']\n",
    "# place_images['pune']=['P', 'Q', 'T', 'U', 'S']\n",
    "# place_images['ahmedabad']= ['Z', 'V', 'W', 'X', 'Y', 'AA']\n",
    "# place_images['malegaon']=  ['V', 'W', 'X', 'Y', 'Z']\n",
    "# place_images['kolkata'] =  ['M','N','O','P','Q','R']\n",
    "# place_images['mumbai']=['P','Q','R','S','U','V']\n",
    "\n",
    "    \n",
    "for place,image_list in place_images.items():\n",
    "\n",
    "    network_filename = data_root+'models/'+model_id+'.hd5'\n",
    "    network = load_model(network_filename, custom_objects={'loss': 'categorical_crossentropy'})\n",
    "    network.summary()\n",
    "    \n",
    "    # compile the model if needed\n",
    "#     utils.util_network.compile_network(network, loss, LR=0.0001)\n",
    "    \n",
    "    for image in image_list:\n",
    "\n",
    "        label_suffix = 'aue'\n",
    "        label_lot = '0'\n",
    "        source = 's2'\n",
    "        resolution = int(tile_resolution)\n",
    "        resampling = 'bilinear'\n",
    "        processing_level = None\n",
    "\n",
    "        look_window = 17\n",
    "        batch_size = 128\n",
    "\n",
    "#         notes = 'application of ' + model_id + ' to 2017 green imagery from ' + place + '(' + image + ')'\n",
    "        notes = 'testing py 3 migration'\n",
    "        print(notes)\n",
    "        \n",
    "        # Set your input validation dataset file here\n",
    "        input_filename = data_root+'models/'+'multi_city_2img-valid.csv'\n",
    "\n",
    "        # Read the validation dataset to a Pandas Dataframe\n",
    "        df = pd.read_csv(input_filename, encoding='utf8')\n",
    "        print(len(df))\n",
    "        \n",
    "        mask = pd.Series(data=np.zeros(len(df.index),dtype='uint8'), index=range(len(df)), dtype='uint8')\n",
    "\n",
    "        mask |= (df['city']==place) & (df['image']==image)\n",
    "\n",
    "        # straight away remove road samples\n",
    "        mask &= (df['lulc']!=6)\n",
    "\n",
    "        # filter others according to specifications\n",
    "        mask &= (df['gt_type']==label_suffix)\n",
    "        mask &= (df['gt_lot']==int(label_lot))\n",
    "        mask &= (df['source']==source)\n",
    "        mask &= (df['resolution']==int(resolution))\n",
    "        mask &= (df['resampling']==resampling)\n",
    "        mask &= (df['processing']==str(processing_level).lower())\n",
    "\n",
    "        print(np.sum(mask))\n",
    "        \n",
    "\n",
    "        # applying the mask to exclude all unnecessary samples\n",
    "        df = df[mask]\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "        print(len(df))\n",
    "        \n",
    "        generator = CatalogGenerator(df,remapping='3cat',look_window=window,batch_size=batch_size,one_hot=3)\n",
    "        \n",
    "        generator.reset()\n",
    "\n",
    "        #predict_generator(generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "        predictions = network.predict_generator(generator, steps=generator.steps, verbose=1,\n",
    "                          use_multiprocessing=True, max_queue_size=40, workers=64,)\n",
    "\n",
    "        print(predictions.shape)\n",
    "        \n",
    "        Yhat = predictions.argmax(axis=-1)\n",
    "        print(Yhat.shape)\n",
    "        \n",
    "        Y = generator.get_label_series().values\n",
    "        print(Y.shape)\n",
    "        \n",
    "        print(\"evaluate validation\")\n",
    "        # hardcoded categories\n",
    "        categories=[0,1,2]\n",
    "        confusion = utils.util_scoring.calc_confusion(Yhat,Y,categories)\n",
    "        recalls, precisions, accuracy = utils.util_scoring.calc_confusion_details(confusion)\n",
    "\n",
    "        # Calculate f-score\n",
    "        beta = 2\n",
    "        f_score = (beta**2 + 1) * precisions * recalls / ( (beta**2 * precisions) + recalls )\n",
    "        f_score_open = f_score[0] \n",
    "        f_score_nonres = f_score[1]  \n",
    "        f_score_res = f_score[2]  \n",
    "        f_score_roads = None#f_score[3]  \n",
    "        f_score_average = np.mean(f_score)\n",
    "        \n",
    "        # expanding lists to match expected model_record stuff\n",
    "        recalls_expanded = [recalls[0],recalls[1],recalls[2],None]\n",
    "        precisions_expanded = [precisions[0],precisions[1],precisions[2],None]\n",
    "        \n",
    "        utils.util_scoring.record_model_application(\n",
    "            model_id, notes, place + '(' + image + ')', label_suffix, resolution, stack_label, feature_count, \n",
    "            generator.look_window,cats_map, \n",
    "            confusion, recalls[0], recalls[1], recalls[2], recalls[3], precisions[0], precisions[1], precisions[2], precisions[3], accuracy, \n",
    "            f_score_open, f_score_nonres, f_score_res, f_score_roads, f_score_average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geoml]",
   "language": "python",
   "name": "conda-env-geoml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
